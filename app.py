# app.py
import gradio as gr
from deepseek_model import DeepSeekAssistant


class DeepSeekUI:
    def __init__(self):
        self.assistant = DeepSeekAssistant()
        self.current_mode = "balanced"
        self.css = """
        .container { max-width: 850px; margin: auto; padding: 20px; }
        .chat-message { padding: 15px; border-radius: 15px; margin: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
        .user-message { background-color: #e3f2fd; text-align: right; margin-left: 20%; }
        .bot-message { background-color: #f5f5f5; margin-right: 20%; }
        .header { text-align: center; padding: 25px; background: linear-gradient(135deg, #2196F3, #1976D2);
                 color: white; border-radius: 15px; margin-bottom: 20px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); }
        .mode-info { margin-top: 10px; padding: 10px; border-radius: 8px; background-color: rgba(255,255,255,0.1); }
        .examples { background-color: #fff; padding: 15px; border-radius: 10px; margin-top: 20px; border: 1px solid #e0e0e0; }
        .mode-description { margin: 10px 0; padding: 10px; border-radius: 8px; background-color: #f8f9fa; 
                          border-left: 4px solid #2196F3; }
        .mode-status { text-align: center; padding: 8px; margin: 10px 0; border-radius: 4px;
                      background-color: #e8f5e9; color: #2e7d32; font-weight: 500; }
        """

    def user_message(self, message, history):
        """Format and add user message to chat"""
        if message.strip() == "":
            return "", history

        history.append({"role": "user", "content": message})
        return "", history

    def bot_message(self, history):
        """Generate and format bot response"""
        if not history or history[-1]["role"] != "user":
            return history

        message = history[-1]["content"]
        response = self.assistant.generate_response(message, history)

        history.append({"role": "assistant", "content": response})
        return history

    def clear_chat(self):
        """Clear chat history"""
        self.assistant.clear_context()
        return []

    def update_mode_and_ui(self, new_mode, chatbot):
        """Update mode and UI elements"""
        try:
            if new_mode != self.current_mode:
                self.assistant.change_mode(new_mode)
                self.current_mode = new_mode

            mode_names = {"fast": "‡πÄ‡∏£‡πá‡∏ß", "balanced": "‡∏™‡∏°‡∏î‡∏∏‡∏•", "smart": "‡∏â‡∏•‡∏≤‡∏î"}
            status = f"‚úì ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏´‡∏°‡∏î{mode_names.get(new_mode, new_mode)}‡πÅ‡∏•‡πâ‡∏ß"

            return (
                self.get_mode_description(new_mode),
                status,
                chatbot if chatbot else [],
            )
        except Exception as e:
            return (
                self.get_mode_description(self.current_mode),
                f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}",
                chatbot if chatbot else [],
            )

    def get_mode_description(self, mode):
        descriptions = {
            "fast": """üöÄ ‡πÇ‡∏´‡∏°‡∏î‡πÄ‡∏£‡πá‡∏ß (Fast Mode)
            ‚Ä¢ ‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß ‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö
            ‚Ä¢ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô
            ‚Ä¢ ‡πÉ‡∏ä‡πâ‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ô‡πâ‡∏≠‡∏¢""",
            "balanced": """‚öñÔ∏è ‡πÇ‡∏´‡∏°‡∏î‡∏™‡∏°‡∏î‡∏∏‡∏• (Balanced Mode)
            ‚Ä¢ ‡∏™‡∏°‡∏î‡∏∏‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
            ‚Ä¢ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î ‡∏Å‡∏≤‡∏£‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î
            ‚Ä¢ ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡πÉ‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°""",
            "smart": """üß† ‡πÇ‡∏´‡∏°‡∏î‡∏â‡∏•‡∏≤‡∏î (Smart Mode)
            ‚Ä¢ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
            ‚Ä¢ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á
            ‚Ä¢ ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥""",
        }
        return descriptions.get(mode, "")

    def create_interface(self):
        with gr.Blocks(css=self.css, theme=gr.themes.Soft()) as interface:
            gr.Markdown(
                """
                <div class="header">
                    <h1>ü§ñ DeepSeek AI Assistant</h1>
                    <p>‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ï‡∏≠‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì</p>
                </div>
                """
            )

            with gr.Row():
                with gr.Column(scale=1):
                    mode_selector = gr.Radio(
                        choices=["fast", "balanced", "smart"],
                        value="balanced",
                        label="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô",
                        interactive=True,
                    )
                with gr.Column(scale=3):
                    mode_info = gr.Markdown(
                        value=self.get_mode_description("balanced"),
                        elem_classes=["mode-description"],
                    )

            status_msg = gr.Markdown(
                value="‚úì ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏ô‡πÇ‡∏´‡∏°‡∏î‡∏™‡∏°‡∏î‡∏∏‡∏•", elem_classes=["mode-status"]
            )

            with gr.Row():
                with gr.Column(scale=4):
                    chatbot = gr.Chatbot(
                        height=600,
                        show_label=False,
                        layout="bubble",
                        bubble_full_width=False,
                        container=True,
                        type="messages",
                        value=[],
                    )

            with gr.Row():
                msg = gr.Textbox(
                    show_label=False,
                    placeholder="‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà...",
                    container=False,
                    scale=8,
                )
                submit = gr.Button("‡∏™‡πà‡∏á", variant="primary", scale=1)

            with gr.Row():
                clear = gr.Button("‡∏•‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤", variant="secondary")
                retry = gr.Button("‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà", variant="secondary")

            gr.Examples(
                examples=[
                    "‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î Python ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå Excel",
                    "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á Machine Learning ‡πÅ‡∏ö‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢",
                    "‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö Database ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£",
                    "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ Data Visualization ‡∏î‡πâ‡∏ß‡∏¢ Python",
                ],
                inputs=msg,
                label="‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°",
            )

            # Event handlers
            mode_selector.change(
                fn=self.update_mode_and_ui,
                inputs=[mode_selector, chatbot],
                outputs=[mode_info, status_msg, chatbot],
            )

            submit.click(
                self.user_message, [msg, chatbot], [msg, chatbot], queue=False
            ).then(self.bot_message, chatbot, chatbot)

            msg.submit(
                self.user_message, [msg, chatbot], [msg, chatbot], queue=False
            ).then(self.bot_message, chatbot, chatbot)

            clear.click(self.clear_chat, None, chatbot, queue=False)
            retry.click(self.bot_message, chatbot, chatbot)

        return interface


if __name__ == "__main__":
    ui = DeepSeekUI()
    interface = ui.create_interface()
    interface.launch(server_name="127.0.0.1", server_port=3000, share=False)
